---
title:  "自然语言处理浅谈"
layout: post
mathjax: true
tags: 人工智能
---

由于人产生的信息普遍以自然语言（而不是语义网）的形式传播，互联网和各种数据库中的这些非结构化数据中蕴藏了价值连城的大量信息。然而，对于计算机而言，理解自然语言相当困难，实际上这可能正是人工智能的核心。然而，我们仍然可以做不少事情。

## 文本的层次结构

文本可以分为由小到大的不同单位：
- 字符是文本最基本的组成单位，例如中文的`我`和英文的`a`都是字符。
- 词素是介于字符与单词间的单位，例如英文中单词`undoable`可视为由词素`un`、`do`、`able`组成。在一些语言如中文，词素这一级可以忽略不计，但对于词素众多而字典资源稀缺的语言，一些通常在词法层面做的处理要改在词素层面做以克服数据稀疏的问题。
- 单词是有单独意义的最小单位，例如中文中的`飞机`和英文中的`aircraft`。
- 句子表达断言、疑问、请求等。
- 段落。在现在主流的语言中，段落间有额外的空白或者由额外的缩进开首，有时还有编号，因而把文本分解成段落通常并不是太困难。

## 常规文本处理程序

1. 语言检测。由于不同语言的差异，先检测语言再用针对对应语言处理的效果通常比较好。检测语言的标准方法是先收集大量已知语言的文本（例如来自维基百科），并统计其中各n-gram的频率，然后对于未知语言的文本，按其中各n-gram的频率用朴素贝叶斯分类器或其它分类器决定文本最可能属于哪个语言。语言检测虽然原理上简单，但某些广泛使用的语言检测工具包所用样本的数据量小得可怜或者模型太小（如连中文常用字都不完整），导致准确性不如人意。
2. 分句。在现在主流的语言中，句子由特定的标点符号（如句号、问号或感叹号）分隔，因而把文本分解成句子通常并不是太困难，只是更准确的分句方法还要考虑句点在引号内或用作小数点之类的情况。但这不是必然的，如古汉语中往往不用标点符号。
3. 分词。单词是众多文本处理的基本单位，因为把句子分解成单词序列是重要的。对于一些语言如英文，由于单词间由空白分隔，这是容易的。但对于中文这种语言，通常要借助字典进行最长前缀切分，即由左到右依次寻找在字典中的最长字符序列。这不一定给出合理的分词，例如在单词不在词典中或有歧义时（如“走上|海|街”和“走|上海街”），但通常效果不错。其中词典即由已知单词组成的列表。虽然可以人手编辑字典，但网络上大量的文本使自动生成字典成为可能，因为单词的特征在于它们出现的频率异常地高。一些有搜索业务的公司开发输入法就是为了收集数据以改善分词。分词后有时会进行一些规范化，如把缩写“don't”转换为“do not”。
4. 词干提取。在一些语言中，单词根据词性、时态、单复数、性别等等有不同形式，但对于信息检索、文本分类与聚类之类基于词包的应用，由于不同形式对应类同的概念，往往被归一化为称为词干的标准形式。各种语言的词干提取算法可参考[Snowball实现](http://snowballstem.org/algorithms/)，大意是按一定规则依次替换各种后缀。

### 消歧义

经常出现一词多义的情况，对于缩写和名字尤其严重，如可能有很多个人叫“张三”、很多个城市都有“北京路”、很多所大学简称“中大”。为了区分一个单词到底是哪个词义，通常的策略是看它邻近的单词，比如说如果“中大”附近有“大学站”、“新亚”或者“港独”则很可能指“香港中文大学”，而如果“中大”附近有“新港西路”或者“1924”则很可能指“中山大学”。

为了实现上述想法，我们需要统计各个词义对应单词与其它词一起出现的概率。幸好，维基百科和百度百科对不同词义有不同页面，可以近似认为页内该单词都是那个词义，这可作为一个出发点。

### 命名实体识别

### 词性标注

### 词组



### 引用解析

句子中常常有“你”、“我”、“它”、“那个”、“这里”之类的代词。为了把句子表示为知识，有必要弄清代词到底在指什么。

### 拼写检查

拼写检查可能是自然语言处理技术中最早得到广泛应用的，众多字处理器都配备了这功能。分词后不出现在字典中的单词就视为是拼写错误。拼写检查系统还可以推荐读音类似的拼写建议，方法通常是找出字典中与之编辑距离最短的单词。对拼写检查感兴趣的话可以参考[GNU Aspell](http://aspell.net/)。

### 词袋

。这个出奇地简单的模型

#### 文本检索

#### 文本分类

#### 文本聚类

#### 情感/观点提取


## 语法

### 解析

## 语义

## 语用

## 语音

### 语音合成

语音合成也就是把文字转换为读出来的声音，用于各种话音播报系统，也用于让视障人士使用计算机的屏幕阅读器。通用语音合成通常的流程为：

1. 利用预先制订的规则把文本转化为音素序列
2. 利用预先制订的规则把各音素转换为声音（还可能按标点符号位置插入停顿）
3. 利用预先制订的规则微调频率、强度、语速等来模拟不同性别、年龄、语气发出的声音

关于规则的形式，可以参考语音合成软件[eSpeak NG](https://github.com/espeak-ng/espeak-ng/tree/master/docs)的文档，它已经支持超过100种语言。虽然需要为每种语言分别编写规则，而且编写时需要一些专门技能，但这基本上是一次性的工作，工作量可以接受，因此要标注大量语音样品的机器学习方法反而没有必要。

语音合成的效果往往显得生硬，但毕竟一般人能听懂它在说什么。

### 语音识别

与语音合成相反，语音识别要把声音转化为文字。由于输入不是精确的，加上一音多字的情况远比一字多音的情况常见，这使语音识别更为困难。语音识别可用于输入文本（较常见于移动设备），也可用于情报工作。通用语音识别通常的流程为：

1. 利用停顿把声音切割为音素序列。
2. 识别各音素。这可能涉及用大量标注语音样本训练出的分类器，也可能是与音素发音规则（语音合成用的）对比。
3. 把音素序列转化为一些可能的文本。这可以通过字典加规则完成。
4. 利用语言模型选取最符合语言特征的文本。最基本的语言模型就是n-gram模型，如“一个”在中文文本中的频率远比“医铬”高，所以选取前者而非后者。不过，小概率的n-gram还是有可能出现的，所以无法做到完全准确，对姓名之类缺陷特别明显。

语音识别已经能达到一定的准确率，足以用于一些非正式场合或有后期人工验证的场合，例如制作字幕时校对往往比重新输入更省时间。另外，对于特殊用途的语音识别系统（如某些声控家电），由于只用区分少数几个命令，准确率可能可接近完美。

除了识别语音的内容，通过对不同变量训练分类器，还可以企图识别语音的其它属性：
- 口音
- 语气
- 说话者性别
- 说话者年龄
- 说话者

这些属性在情报工作中可能有参考价值。然而，由于声音容易通过录音仿冒，又有人练习伪声，声纹识别用于门禁系统之类并不安全。

## 应用


### 通顺/程度

### 问答系统

不妨在Emacs中输入`Alt-x doctor`进入与精神科医生的模拟聊天，体验一下多年前的聊天系统能做到什么程度。这个写于1985年的程序原理上可追溯到始于1964年的ELIZA，它的[源代码](http://git.savannah.gnu.org/cgit/emacs.git/tree/lisp/play/doctor.el)只有1625行左右，稍为读一下就可以发现它实际上先查找已知场景的关键词，然后按为各场景定制的规则之一生成回答，没有找到则用通用的句子或回忆前面的对话。

现在的聊天系统则主要依赖于巨大的数据量，即时通信、论坛、博客和其它社交平台的运营者能轻易采集大量真实的对话。于是当你向系统说一句话，它就用信息检索的方法搜索类似的一句话，然后把搜索到的话的回应返回给你。因为返回的实际上是别人写的话，这巧妙地避开了文本生成的难题，但几乎完全忽略上下文。一种修正是用前面对话中的词扩展查询。

### 摘要

对于长篇大论的文章，我们往往想了解文章大概在说什么才决定是否看下去。我们希望在没有小编的情况下自动生成摘要，由于文本生成的困难性，我们并不指望机器能自己写出总结，而是希望找出文章的中心句。通常的做法是先找出文章中频率特别高的词作为关键词，然后找出富含关键词的句子。

### 文本生成

如果只用生成没有太大意义的文本，例如垃圾邮件或者网上评论，用基于Markov链的方法生成随机文本即可。例如假定我们收集了汉语的1-gram和2-gram频率数据，则为了一个随机句子，首先按各汉字的频率分布随机选出一个字作为开首，然后不断按给定上一字情况下下一字的频率分布随机选取下一字，直到选取到句号。

基于规则

## 资源

- [Wordnet目录](http://globalwordnet.org/wordnets-in-the-world/)提供了指向多种语言Wordnet的链接。

## 结语

与编程语言不同，由于自然语言是长期演化的群体产物，并且仍然在变化之中，因此缺乏概念完整性，准确概括自然语言是几乎不可能的任务。虽然人们企图为自然语言建立层次模型，但并不能把握自然语言中错综复杂的联系。
